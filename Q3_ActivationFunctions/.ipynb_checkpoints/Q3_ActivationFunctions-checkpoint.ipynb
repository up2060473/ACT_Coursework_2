{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building CNNs for photo classification using PyTorch: How Choice of activation function impacts model accuracy and runtime. \n",
    "\n",
    "In this notebook, we build a Convolution Neural Network (CNN) to classify bird species from images using PyTorch. We also investigate how the choice of activation function changes the model results and runtime.\n",
    "\n",
    "Assumed background: Readers have some basic knowledge of CNNs and ML techniques and have read through ../Q2_CNN/Q2_CNN_Birds.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Dataset:\n",
    "- We will use the Birds classification dataset from Rahma Sleam, Kaggle.\n",
    "- There are 6 types target classes\n",
    "    - American Goldfinch\n",
    "    - Barn Owl\n",
    "    - Carmine Bee-Eater\n",
    "    - Downy Woodpecker\n",
    "    - Emperor Penguin\n",
    "    - Flamingo\n",
    "- All these birds have their own distinct features as they range over across a wide range of habitats - see link for more detail.\n",
    "\n",
    "We Will:\n",
    "- Load an image dataset\n",
    "- Explore how the dataset is distributed among each class to allow investigation into any biases if required\n",
    "- Apply preprocessing and augmentation\n",
    "- Train a CNN \n",
    "- Evaluate its performance\n",
    "- Loop over various activation functions and compare results. \n",
    "    - List of activation functions we will investigate:\n",
    "        - Relu, Tanh, Leaky_relu and sigmoid\n",
    "\n",
    "_Link to dataset: https://www.kaggle.com/datasets/rahmasleam/bird-speciees-dataset All rights to their respective owners_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries\n",
    "Here, we import the revelent packages from PyTorch, Torchvision and some useful python libraries that will help us to visualise and manipulate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T06:43:21.718657Z",
     "iopub.status.busy": "2026-01-16T06:43:21.717860Z",
     "iopub.status.idle": "2026-01-16T06:43:27.707434Z",
     "shell.execute_reply": "2026-01-16T06:43:27.704871Z",
     "shell.execute_reply.started": "2026-01-16T06:43:21.718520Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Importing Libraries \n",
    "## To be updated to be stored in a dependancies folder\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device allocation\n",
    "We leverage faster runtimes on GPU when available. Note that this notebook was set up using CPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T06:43:27.711341Z",
     "iopub.status.busy": "2026-01-16T06:43:27.710589Z",
     "iopub.status.idle": "2026-01-16T06:43:27.724995Z",
     "shell.execute_reply": "2026-01-16T06:43:27.722979Z",
     "shell.execute_reply.started": "2026-01-16T06:43:27.711287Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Device\n",
      "GPU Available:  False\n",
      "Switching to CPU.... \n",
      "May result in slower performance\n"
     ]
    }
   ],
   "source": [
    "## Which device?\n",
    "print(\">>> Device\\nGPU Available: \", torch.cuda.is_available())\n",
    "\n",
    "## Setting Device\n",
    "if torch.cuda.is_available() == False:\n",
    "    print(\"Switching to CPU.... \\nMay result in slower performance\")\n",
    "    device = \"cpu\"\n",
    "else:\n",
    "    print(\"Cuda GPU found, switching device to increase performance\")\n",
    "    device = \"cuda\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforms and augmentation\n",
    "We apply transforms to normalise and standardise data to allow better model efficiency.\n",
    "Random horizontal flips and randome rotations are applied across each class to improve model generalisation. Note that the transforms are consistent across each class, as the data is well-distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T06:43:27.727351Z",
     "iopub.status.busy": "2026-01-16T06:43:27.726847Z",
     "iopub.status.idle": "2026-01-16T06:43:27.737672Z",
     "shell.execute_reply": "2026-01-16T06:43:27.735611Z",
     "shell.execute_reply.started": "2026-01-16T06:43:27.727305Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    ## Transforms data when called\n",
    "    ## Resize: Ensures that all images have same size - needed for batching\n",
    "    ## Rand Horizontal Flip: Used to augment data\n",
    "    ## Rand Rotation: Used to augment data\n",
    "    ## To Tensor: converts to a PyTorch Tensor, needed for processing\n",
    "        ## (H,W,C) -> (C,H,W)\n",
    "    ## Normalises data to mean=std=0.5,0.5,0.5 \n",
    "    transforms.Resize((128,128)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset\n",
    "\n",
    "To load the dataset, we use torchvision.datasets.ImageFolder which assumes:\n",
    "- One folder per class\n",
    "- Images are inside each folder\n",
    "\n",
    "Then, it is good practice to investigate how the data is distributed among each class. This will help us to determine whether we need to eliminate any biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T06:45:30.576357Z",
     "iopub.status.busy": "2026-01-16T06:45:30.575361Z",
     "iopub.status.idle": "2026-01-16T06:45:30.610783Z",
     "shell.execute_reply": "2026-01-16T06:45:30.609030Z",
     "shell.execute_reply.started": "2026-01-16T06:45:30.576296Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Investigating distribution\n",
      "AMERICAN GOLDFINCH : 143\n",
      "BARN OWL : 129\n",
      "CARMINE BEE-EATER : 131\n",
      "DOWNY WOODPECKER : 137\n",
      "EMPEROR PENGUIN : 139\n",
      "FLAMINGO : 132\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../birds_dataset_2/Bird Speciees Dataset/\"\n",
    "\n",
    "## Loading the total data \n",
    "data = torchvision.datasets.ImageFolder(\n",
    "    ## Loading data usng Image Folder\n",
    "    ## Root: where the data is stored\n",
    "    ## Transform: applies the transforms / augmentations we defined earlier\n",
    "    root = data_path,\n",
    "    transform = transform,\n",
    ")\n",
    "\n",
    "## Investigating distribution\n",
    "classes = data.classes\n",
    "print(\">>> Investigating distribution\")\n",
    "## Counter counts how may times each bird appears\n",
    "class_counts = Counter(data.targets)\n",
    "for index, count in class_counts.items():\n",
    "    ## Loops through each class index and its image count\n",
    "    print(f\"{data.classes[index]} : {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-15T08:09:08.185728Z",
     "iopub.status.busy": "2026-01-15T08:09:08.184577Z",
     "iopub.status.idle": "2026-01-15T08:09:08.205765Z",
     "shell.execute_reply": "2026-01-15T08:09:08.201402Z",
     "shell.execute_reply.started": "2026-01-15T08:09:08.185666Z"
    },
    "tags": []
   },
   "source": [
    "## Train / Test Split\n",
    "\n",
    "We now will split the dataset into a 80% : 20% split for training and testing\n",
    "- 80% of the total data will be used to train the model\n",
    "- 20% of the total data will be used to test the model and produce accuracy scores\n",
    "\n",
    "This is common practice in ML because:\n",
    "- It can help to ensure that the CNN is not simply memorising patterns from training. This helps to prevent overfitting:\n",
    "- Overfitting occurs when the CNN fits the training data too closely, that it cannot provide good predictions on unseen data\n",
    "\n",
    "Batch size is a training hyperparameter that defines how many samples a neural network processes at once, before updating its weights during training. Here, it is set to 16. \n",
    "\n",
    "In PyTorch, data is loaded through something called Dataloaders which do the following:\n",
    "- Load the data in batches\n",
    "- Shuffle training data\n",
    "- Improve perfomance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Setting batch size to 16\n",
    "## Model will process 16 images at a time before updating its weights\n",
    "batch_size = 16\n",
    "print(\">>> Splitting data into 80% training and 20% testing\")\n",
    "\n",
    "## Calculating the training and testing sizes\n",
    "## Note: test_size best not be deinfed as int(0.2 * len(data)) due to potential rounding error\n",
    "## random_split: sing PyTorch's built in random splitter\n",
    "train_size = int(0.8 * len(data))\n",
    "test_size = len(data) - train_size\n",
    "train_dataset, test_dataset = random_split(data, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    ## Loading training set\n",
    "    ## shuffle: randomly shuffles the data during training\n",
    "    ## num_workers = 0: loads data using main process, no parallel loading (sciserver friendly)\n",
    "    train_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    num_workers = 0\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    ## Loading testing set\n",
    "    ## shuffle: keeps data consecutive during testing\n",
    "    ## num_workers = 0: loads data using main process, no parallel loading (sciserver friendly)\n",
    "    test_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False,\n",
    "    num_workers = 0\n",
    ")\n",
    "print(\">>> Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising data\n",
    "\n",
    "Its common practice to visualise the data before training a CNN. This has many benefits:\n",
    "- Ensure the images are loading correctly\n",
    "- To visualise how the data is being augmentated - useful when troubleshooting ie if the intensity needs to be higher / lower\n",
    "- To ensure that the images are the same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    ## Helper function to load image\n",
    "    ## img: Reverses the normalisation applied in the transform \n",
    "    ## npimg: Covnerts PyTorch tensor to np.array - readabl by matplotlib\n",
    "    ## np.transpose: Ensures that the height, width, channels are in correct order\n",
    "    ## plt.imshow(...): Load image grid\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Example images from the training dataset\")\n",
    "    plt.show()\n",
    "    \n",
    "## Calling helper function and choosing images from first data batch\n",
    "## dataiter: Converts train_loader to an iterator - allow fetching of batches\n",
    "## images, labels = next(dataiter: Gets the first batch)\n",
    "## imshow(...): Calls function above to show images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print(\">>> Notice how there are 16 images (defined from the batch_size), and that each time there is a different set of images (as data is shuffled)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining CNN Architecture, training, testing and evaluation\n",
    "\n",
    "Whilst the notebook in ../Q2_CNN seperates the CNN architecture, training, testing and evalutaion in seperate code blocks, here will will combine them into one as we are iterating over each activation function. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## List of activation functions to be investigated\n",
    "activation_functions = [torch.nn.functional.relu, torch.tanh, torch.nn.functional.leaky_relu, torch.sigmoid]\n",
    "\n",
    "## Where results will be stored\n",
    "results = []\n",
    "\n",
    "for activation_fn in activation_functions:\n",
    "    ## Loops over every activation function (Starts runtime)\n",
    "    ## Defines CNN Architecture \n",
    "    ## Trains network and ends runtime\n",
    "    ## Tests network and saves results\n",
    "    print(\"\\n\\n>>> Training with activation function: \", activation_fn.__name__)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    ## Defining a CNN\n",
    "    class Net(nn.Module):\n",
    "    ## Definition of CNN Architecture\n",
    "    ## Net(nn.Module) creates a custom CNN from PyTorch\n",
    "        def __init__(self, num_classes = 6, activation_fn=F.relu):\n",
    "    ## num_classes = 6: There are 6 types of bird\n",
    "        ## input_size = 128: Input images been resized to 128\n",
    "        ## super().__init__(): Initialisation\n",
    "        ## Definition of convolutional layers\n",
    "            ## conv1: Input 3 channels (RGB), outputs 6 feature maps, 5x5 kernel\n",
    "            ## pool: Max pooling: reduces spatial dimensions by taking the maximum value for every 2x2 grid\n",
    "            ## conv2: Input 6 channels, output 16 channels, 5x5 kernel\n",
    "        ## Definition of Fully Connected Layers\n",
    "            ## fc1: 16*29*29 input features (comes from size of feature maps after conv layers), 120 outputs\n",
    "            ## fc2: 120 inputs, 84 outputs\n",
    "            ## fc3: 84 inputs, 6 outputs (classes)\n",
    "        ## Activation function initilised to relu, but will be changed\n",
    "            \n",
    "            super().__init__()\n",
    "            self.activation_fn = activation_fn\n",
    "            \n",
    "            ## Conv layers\n",
    "            self.conv1 = nn.Conv2d(3,6,5)\n",
    "            self.pool = nn.MaxPool2d(2,2)\n",
    "            self.conv2 = nn.Conv2d(6,16,5)\n",
    "        \n",
    "            ## FN layers\n",
    "            self.fc1 = nn.Linear(16*29*29, 120)\n",
    "            self.fc2 = nn.Linear(120, 84)\n",
    "            self.fc3 = nn.Linear(84, num_classes)\n",
    "            \n",
    "        def forward(self, x):\n",
    "        ## Forward defines how data flows through a network\n",
    "        ## X goes through:\n",
    "            ## conv layer 1\n",
    "            ## conv layer 2\n",
    "            ## Image gets flattened to a vector for the FC layers\n",
    "            ## FC Layer 1\n",
    "            ## FC Layer 2\n",
    "            ## FC Layer 3 - this is the output layer\n",
    "            ## conv layers, relu and pooling\n",
    "            \n",
    "            x = self.pool(self.activation_fn(self.conv1(x)))\n",
    "            x = self.pool(self.activation_fn(self.conv2(x)))\n",
    "\n",
    "            x = torch.flatten(x, 1)\n",
    "\n",
    "            x = self.activation_fn(self.fc1(x))\n",
    "            x = self.activation_fn(self.fc2(x))\n",
    "\n",
    "            x = self.fc3(x)\n",
    "            return x\n",
    "\n",
    "    ## Initiate Network\n",
    "    net = Net(num_classes=6, activation_fn=activation_fn)\n",
    "    print(net)\n",
    "\n",
    "    ## Defining cross entropy loss and adam optimiser (See notebook in ../Q2_CNN)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "    net.to(device)\n",
    "\n",
    "\n",
    "\n",
    "    for epoch in range(10):\n",
    "    ## Training loop - this is where the model trains on the data\n",
    "    ## Epoch: How many times teh model goes through the training set\n",
    "    ## running_loss: tracks the loss\n",
    "        running_loss = 0.0\n",
    "    \n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            ## Loops over training data\n",
    "            ## inputs = image batch, labels = corresponding classes\n",
    "            ## inputs.to(device) / labels.to(device) moves the current batch to the device chosen\n",
    "            ## optimiser.zero_grad() resets the loss gradient\n",
    "            ## outputs = net(inputs) sends data through CNN\n",
    "            ## Definition of loss function as defined above\n",
    "            ## loss.backward(): Computes the loss and finds which neurons contributed most \n",
    "            ## optimiser.step(): Adam optimiser updates the model weights \n",
    "            ## running_loss(): Tracks the running loss\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "            ## Print loss every 10 batches\n",
    "            if (i+1) % 10 ==0:\n",
    "                print(f\"Epoch {epoch+1}, Batch {i+1} Loss: {running_loss / 10:.3f}\")\n",
    "                running_loss = 0.0\n",
    "    ## Ending and calculating runtime\n",
    "    end_time = time.time()\n",
    "    runtime = end_time - start_time\n",
    "    print(\"Finished Training for \", activation_fn.__name__)\n",
    "\n",
    "    ## Save the model\n",
    "    PATH = str(\"./bird_classifier_\"+ activation_fn.__name__+\".pth\")\n",
    "    torch.save(net.state_dict(), PATH)\n",
    "    print(f\"\\n\\n>>> Saved model to ./bird_classifier_{activation_fn.__name__}.pth\")\n",
    "\n",
    "    ## Creating dictionaries that track proedictions\n",
    "    net.eval()\n",
    "    correct_pred = {classname: 0 for classname in classes}\n",
    "    total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "    ## Testing model and saving preictions\n",
    "    print(\">>> Testing model\")\n",
    "    with torch.no_grad():\n",
    "        ## torch.no_grad(): Does not calculate gradient loss which is uncessisary when testing.\n",
    "        for data in test_loader:\n",
    "            ## loop through each batch in  the testing dataset\n",
    "            ## Moves the current batch to the device\n",
    "            ## outputs = net(images): Sends data through CNN\n",
    "            ## torch.max: Returns class with highest predicted score for each image\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "        \n",
    "            for label, prediction in zip(labels, predictions):\n",
    "                ## If prediction matches the true label, correct_pred increases for that class\n",
    "                ## Every loop increases total_pred for that class \n",
    "                label = label.item()\n",
    "                prediction = prediction.item()\n",
    "                if label == prediction:\n",
    "                    correct_pred[classes[label]] += 1\n",
    "                total_pred[classes[label]] += 1\n",
    "            \n",
    "    for classname, correct_count in correct_pred.items():\n",
    "        ## Loop over each correct prediction\n",
    "        ## accuracy: computs the accuracy for each class\n",
    "        ## Appends this to a dictionary\n",
    "        ## overall accuracy then computed\n",
    "        ## Appended to dictionay\n",
    "        ## Results are then converted to a panda dataframe\n",
    "        ## Results displayeds\n",
    "        accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "        results.append({\n",
    "            \"Activation Function: \": activation_fn.__name__,\n",
    "            \"Class: \": classname,\n",
    "            \"Accuracy: \": accuracy\n",
    "        })\n",
    "        \n",
    "    overall_correct = sum(correct_pred.values())\n",
    "    overall_total = sum(total_pred.values())\n",
    "    overall_accuracy = 100 * float(overall_correct) / overall_total\n",
    "    results.append({\n",
    "        \"Overall Accuracy: \": overall_accuracy,\n",
    "        \"Runtime: \": runtime\n",
    "    })\n",
    "    \n",
    "results_df = pd.DataFrame(results)\n",
    "display(results_Df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources used in this Notebook\n",
    "\n",
    "**Code inspired by**\n",
    "1. Code heavily inspired by ../Q2_CNN notebook and references listed at the end of that notebook - this code has just been modified to iterate over a list of activation functions.   \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (py39)",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
